### SYSTEM PROMPT ###
You are an optimization modeling assistant specialized in retail supply chains.

Goal: semantic fidelity. The MILP must implement the structurally active mechanisms implied by `data` and the scenario text, not merely compile.

Execution contract:
- The scenario JSON is pre-loaded as a Python dict named `data`. Do NOT modify `data`.
- Do NOT perform any file I/O (no open(), json.load(), Path.read_text(), etc.).

Modeling requirements:
- Implement a mixed-integer linear program (MILP) in Python using gurobipy.
- Include all modules that are structurally active in `data` (and omit inactive ones), such as:
  perishability with remaining-life indexing and aging transitions, shared-capacity coupling,
  directed substitution routing with demand/sales conservation, transshipment flows,
  lead times, discrete procurement (MOQ / pack size / fixed ordering), budgets, and waste caps.

Data semantics (must follow):
- Demand allocation: if `data` contains `demand_curve` by product and period and `demand_share` by location, interpret `demand_curve[p][t]` as total demand for product p in period t, and allocate location demand as `Dem[p,l,t] = demand_curve[p][t] * demand_share[l]`.
- Production/procurement capacity: if `data` contains `production_cap[p][t]` with no location index, interpret it as a global (network-wide) capacity for product p in period t, enforced as `sum_l inflow[p,l,t] <= production_cap[p][t]` (where inflow is production/order quantity delivered in that period, consistent with lead times).

Naming contract (required for automatic semantic checking):
- Use the following variable dictionaries with exactly these names when active:
  I (inventory by remaining life), y (sales/consumption), W (waste),
  Q (orders), L (lost sales), d (direct demand served),
  S (substitution routing), X (transshipment), z (order trigger), n (pack integer).
- When adding constraints, set the `name=` field using these prefixes (plus indices):
  demand_route, sales_conservation, availability, expire_clear, leadtime, returns,
  fresh_inflow, aging, storage_cap, prod_cap, labor_cap, moq_lb, moq_ub,
  pack, budget, wastecap.

Objective (reference semantics):
- Minimize total cost including all cost terms present in `data`: holding/inventory, waste, and lost-sales penalties;
  plus purchasing/ordering costs if provided; plus (if enabled) transshipment cost and fixed ordering cost.
- If a cost term is missing in `data`, treat it as zero; do not invent extra data.

Solving and output:
- Call the solver and print the solver status and the objective value (if available).

Return:
- Output a single Python script as plain text.
- No Markdown, no code fences, and no comments in the returned code.

### USER PROMPT ###
[SCENARIO]
Family: F1 (Core Operations)
Archetype: retail_f1_high_waste
Scenario ID: retail_f1_high_waste_v2

Business narrative:
This scenario keeps the same basic single-echelon structure as the core operations baseline but represents categories where waste is extremely expensive, such as highly perishable or sensitive products. The retailer still serves exogenous seasonal demand from local inventories at distribution centers with no transshipment and no backorders. Any units that must be discarded because they are no longer usable incur a much higher penalty than in the baseline, creating strong pressure to avoid overstocking.

Structure cues:
- The network is the same as in retail_f1_base: multiple products, multiple locations that directly serve final demand, and per-product production capacities in each period.
- Inventory is held at each location, evolves from period to period by adding local production and subtracting sales and waste, and is never allowed to go negative. Unserved demand is treated as lost sales and penalized as in the baseline.
- Storage capacity constraints by location and period must still be respected using product-specific storage usage and the location capacities from the JSON.
- The substitution pattern, absence of transshipment, zero lead times, and effectively non-binding labor capacities are the same as in the baseline scenario.
- The only intended structural change is in the cost weights: waste costs in the JSON are much larger, so discarding inventory is heavily discouraged, but the constraint system itself is not altered.
- The objective continues to minimize the sum of holding costs, waste costs, and lost sales penalties over all products, locations, and periods.

Operational context:
- The JSON contains the number of time periods, the list of products, and the list of locations
  directly as top-level fields (for example: "periods", "products", "locations").
- Cost parameters such as holding, lost-sales, waste, purchasing, and any fixed ordering costs
  are stored in the "costs" section of the JSON.
- Capacity and operational limits such as storage capacity, production capacity, labor capacity,
  shelf life, lead times, minimum order quantities, pack sizes, and any waste or budget limits
  are stored in fields such as "cold_capacity", "production_cap", "labor_cap", "shelf_life",
  "lead_time", "constraints", and "network".
- Scenario-level control parameters such as global minimum order quantities, pack sizes, fixed
  ordering costs, per-period budgets, and waste caps are provided as scalar fields inside the
  "constraints" and "costs" sections and should be applied uniformly across products and locations
  unless the scenario description explicitly specifies otherwise.
- Substitution and transshipment structures are encoded in the "network" section, for example
  as substitution edges or transshipment edges between locations.
- The model should respect all of these fields exactly as given and interpret them in a way
  consistent with the scenario description.

JSON data (do not modify):
The evaluation harness loads the JSON for this scenario into a Python variable
called `data`. Your code should read all sets and parameters from `data` using
these fields and must not change any numeric values or perform any file I/O
(for example, do not call open or json.load).

[INSTRUCTION]
Using ONLY the information above, write a complete Python script that:

1) Imports gurobipy (import gurobipy as gp; from gurobipy import GRB),
2) Assumes the JSON has already been loaded into a Python variable called `data`,
3) Builds and solves a mixed-integer linear program that reflects the business
   description and the structure implied by the JSON fields (including capacities,
   shelf life, lead times, substitution edges, transshipment edges, and other keys/conditions present in `data`),
4) Prints the solver status and the optimal objective value.

Do not invent extra data. Do not change any numbers from the JSON.
Return ONLY the Python source code as plain text, with no comments and no Markdown.