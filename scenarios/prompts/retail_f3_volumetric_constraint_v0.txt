You are an optimization modeling assistant specialized in retail supply chains.

Goal: semantic fidelity. The MILP must implement the structurally active mechanisms implied by `data` and the scenario text, not merely compile.

Execution contract:
- The scenario JSON is pre-loaded as a Python dict named `data`. Do NOT modify `data`.
- Do NOT perform any file I/O (no open(), json.load(), Path.read_text(), etc.).

Modeling requirements:
- Implement a mixed-integer linear program (MILP) in Python using gurobipy.
- Include all modules that are structurally active in `data` (and omit inactive ones), such as:
  perishability with remaining-life indexing and aging transitions, shared-capacity coupling,
  directed substitution routing with demand/sales conservation, transshipment flows,
  lead times, discrete procurement (MOQ / pack size / fixed ordering), budgets, and waste caps.

Data semantics (must follow):
- Demand allocation: if `data` contains `demand_curve` by product and period and `demand_share` by location, interpret `demand_curve[p][t]` as total demand for product p in period t, and allocate location demand as `Dem[p,l,t] = demand_curve[p][t] * demand_share[l]`.
- Production/procurement capacity: if `data` contains `production_cap[p][t]` with no location index, interpret it as a global (network-wide) capacity for product p in period t, enforced on orders/production decisions as `sum_l Q[p,l,t] <= production_cap[p][t]`. Lead times (if any) only shift arrivals across periods; do NOT reinterpret `production_cap` as an arrival/inflow cap.

Naming contract (required for automatic semantic checking):
- Use the following variable dictionaries with exactly these names when active:
  I (inventory by remaining life), y (sales/consumption), W (waste),
  Q (orders), L (lost sales), d (direct demand served),
  S (substitution routing), X (transshipment), z (order trigger), n (pack integer).
- When adding constraints, set the `name=` field using these prefixes (plus indices):
  demand_route, sales_conservation, availability, expire_clear, leadtime, returns,
  init, fresh_inflow, aging, storage_cap, prod_cap, labor_cap, moq_lb, moq_ub,
  pack, budget, wastecap.

Objective (reference semantics):
- Minimize total cost including all cost terms present in `data`: holding/inventory, waste, and lost-sales penalties;
  plus purchasing/ordering costs if provided; plus (if enabled) transshipment cost and fixed ordering cost.
- If a cost term is missing in `data`, treat it as zero; do not invent extra data.

Solving and output:
- Call the solver and print the solver status and the objective value (if available).

Return:
- Output a single Python script as plain text.
- No Markdown, no code fences, and no comments in the returned code.

[SCENARIO]
Family: F3 (Shared Resources and Capacity)
Archetype: retail_f3_volumetric_constraint
Scenario ID: retail_f3_volumetric_constraint_v0

Business narrative:
One product—typically a bulky premium item—uses much more storage volume per unit than the others. Storage capacity at each location becomes tight primarily because of this product, forcing the retailer to choose between stocking bulky high-margin units and smaller items. All demand remains local and exogenous, with no transshipment or backorders.

Structure cues:
- The overall structure and shared storage framework match retail_f3_storage_bottleneck.
- Product-specific storage usage parameters in the JSON are much larger for the premium product than for other SKUs. These usage factors must be applied when enforcing the shared storage limit at each location and period.
- Inventory cannot be negative and is updated based on previous stock, local production, sales, and waste.
- There is no transshipment, lead times are zero, and substitution behavior follows the JSON graph.
- The objective is to minimize total cost under capacity constraints that make the volumetrically heavy premium product particularly expensive in terms of space.

Operational context:
- The JSON contains the number of time periods, the list of products, and the list of locations
  directly as top-level fields (for example: "periods", "products", "locations").
- Cost parameters such as holding, lost-sales, waste, purchasing, and any fixed ordering costs
  are stored in the "costs" section of the JSON.
- Capacity and operational limits such as storage capacity, production capacity, labor capacity,
  shelf life, lead times, minimum order quantities, pack sizes, and any waste or budget limits
  are stored in fields such as "cold_capacity", "production_cap", "labor_cap", "shelf_life",
  "lead_time", "constraints", and "network".
- Scenario-level control parameters such as global minimum order quantities, pack sizes, fixed
  ordering costs, per-period budgets, and waste caps are provided as scalar fields inside the
  "constraints" and "costs" sections and should be applied uniformly across products and locations
  unless the scenario description explicitly specifies otherwise.
- Substitution and transshipment structures are encoded in the "network" section, for example
  as substitution edges or transshipment edges between locations.
- The model should respect all of these fields exactly as given and interpret them in a way
  consistent with the scenario description.

JSON data (do not modify):
The evaluation harness loads the JSON for this scenario into a Python variable
called `data`. Your code should read all sets and parameters from `data` using
these fields and must not change any numeric values or perform any file I/O
(for example, do not call open or json.load).

[INSTRUCTION]
Using ONLY the information above, write a complete Python script that:

1) Imports gurobipy (import gurobipy as gp; from gurobipy import GRB),
2) Assumes the JSON has already been loaded into a Python variable called `data`,
3) Builds and solves a mixed-integer linear program that reflects the business
   description and the structure implied by the JSON fields (including capacities,
   shelf life, lead times, substitution edges, transshipment edges, and other keys/conditions present in `data`),
4) Prints the solver status and the optimal objective value.

Do not invent extra data. Do not change any numbers from the JSON.
Return ONLY the Python source code as plain text, with no comments and no Markdown.
