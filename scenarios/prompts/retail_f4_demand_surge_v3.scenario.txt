[SCENARIO]
Family: F4 (Dynamics and Disruptions)
Archetype: retail_f4_demand_surge
Scenario ID: retail_f4_demand_surge_v3

Business narrative:
The retailer experiences a single-period viral demand spike where demand suddenly multiplies for all products. Production capacity and other structural elements remain unchanged; only the magnitude of demand in that period is much higher. The retailer must decide whether to build extra inventory in advance or accept lost sales during the surge.

Structure cues:
- The inventory and production structure is the same as in the base scenario.
- In the JSON, one mid-horizon period has demand for each product scaled up by a large factor, representing the surge. This period is treated as having much higher exogenous demand.
- Inventory stays non-negative and is updated using previous stock, current production, sales, and waste.
- Storage capacity and substitution behavior are unchanged, there is no transshipment, and lead times remain effectively zero.
- The objective is to minimize total cost, with the demand spike increasing the importance of planning ahead for that particular period.

=============================================================================
MODELING GUIDELINES
=============================================================================
[CORE RULES]
- `data` is a pre-loaded Python dict. Do not modify it.
- No file I/O. Never invent missing data.
- Never hard-code numeric values.
- Output must be plain Python code. No prose, no markdown, no comments.

[DATA FORMAT]
- sub_edges: [[p_from, p_to], ...] means p_from's demand can be served by p_to's inventory.
- trans_edges: [[loc_from, loc_to], ...] for transshipment.
- demand_share: {location: scalar}, NOT nested by product.
- demand = demand_curve[p][t-1] * demand_share[l]  (demand_curve is 0-indexed)
- Time indexing: 1-based (t = 1, 2, ..., T).

[SUBSTITUTION SEMANTICS - CRITICAL]
Edge [p_from, p_to] = "upward substitution": p_to can serve p_from's demand.
S[p_from, p_to, l, t] = quantity of p_from's demand served by p_to.

Build edge mappings BEFORE constraints:
  outgoing_edges = {p: [] for p in products}
  incoming_edges = {p: [] for p in products}
  for p_from, p_to in sub_edges:
      outgoing_edges[p_from].append(p_to)  # p_from sends demand OUT to p_to
      incoming_edges[p_to].append(p_from)  # p_to receives requests IN from p_from

Compute substitution flows for each product p:
  outbound = sum S[p, pt, l, t] for pt in outgoing_edges[p]  # demand p sends out
  inbound  = sum S[pf, p, l, t] for pf in incoming_edges[p]  # requests p receives

Substitution constraints:
  demand_route: outbound <= demand[p,l,t]  (can't substitute more than own demand)
  sales_conservation: sum_a(y[p,l,t,a]) + L[p,l,t] = demand[p,l,t] + inbound - outbound

[SHELF-LIFE / AGING]
- Life buckets: a = 1 (expiring) to a = shelf_life[p] (freshest)
- Aging: I[p,l,t+1,a] = I[p,l,t,a+1] - y[p,l,t,a+1]  (for a < shelf_life, t < T)
- Expiration: W[p,l,t] = I[p,l,t,1] - y[p,l,t,1]
- Availability: y[p,l,t,a] <= I[p,l,t,a]
- Holding cost: apply only to a >= 2 (not expiring bucket a=1)

[FRESH INFLOW - BOUNDARY CONDITIONS]
Fresh inventory enters at a = shelf_life[p]:
  if t > lead_time[p]:
      I[p,l,t,shelf_life] = Q[p,l,t-lead_time]
  else:
      I[p,l,t,shelf_life] = 0
NEVER access Q[p,l,0] or negative indices - they don't exist.

[INITIALIZATION at t=1]
  I[p,l,1,a] = 0  for a < shelf_life[p]  (non-fresh buckets empty)
  I[p,l,1,shelf_life] = Q[p,l,1] if lead_time=0, else 0

[AGING BOUNDARY at t=T]
Do NOT add aging constraints for t=T, as they would reference I[p,l,T+1,a] which doesn't exist.

[VARIABLE NAMING]
Use these exact names:
- I[p,l,t,a]: inventory by product, location, period, remaining life bucket
- y[p,l,t,a]: sales/consumption from life bucket
- W[p,l,t]: waste (expired inventory)
- Q[p,l,t]: orders/production
- L[p,l,t]: lost sales
- S[p_from,p_to,l,t]: substitution flow (only if sub_edges nonempty)

[SOLVING]
- Gurobi params: OutputFlag=0, Threads=1, Seed=0.
- Print: print(f"status: {m.Status}")
- If OPTIMAL: print(f"objective: {m.ObjVal}")

=============================================================================
DATA ACCESS
=============================================================================

The evaluation harness loads the JSON into a Python variable called `data`.
Read all parameters from `data`. Do not use file I/O.

Key fields:
- data["periods"]: int (number of time periods)
- data["products"]: list of product IDs
- data["locations"]: list of location IDs
- data["shelf_life"][p]: int, life buckets per product
- data["lead_time"][p]: int, delivery delay (may be 0)
- data["demand_curve"][p]: list (0-indexed, use [t-1] for period t)
- data["demand_share"][l]: scalar share per location
- data["network"]["sub_edges"]: [[p_from, p_to], ...]
- data["network"]["trans_edges"]: [[l_from, l_to], ...]
- data["costs"]["inventory"][p], ["waste"][p], ["lost_sales"][p], ["purchasing"][p]
- data["production_cap"][p]: list or scalar (per period)
- data["cold_capacity"][l], data["cold_usage"][p]



[INSTRUCTION]
Write a complete GurobiPy script that:
1) Imports gurobipy (import gurobipy as gp; from gurobipy import GRB)
2) Reads all parameters from `data` (already loaded)
3) Builds edge mappings for substitution BEFORE creating constraints
4) Creates all decision variables with correct indices
5) Sets objective: minimize inventory + waste + lost_sales + purchasing costs
6) Adds all constraints respecting boundary conditions:
   - Initialization at t=1
   - Aging only for t < T
   - Fresh inflow with lead_time check
   - Substitution if sub_edges nonempty
7) Sets Gurobi params: OutputFlag=0, Threads=1, Seed=0
8) Prints status always; prints objective only if OPTIMAL

Return ONLY Python code. No markdown, no comments, no explanations.
